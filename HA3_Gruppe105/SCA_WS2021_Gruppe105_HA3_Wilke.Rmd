---
title: "SCA_WS2021_Gruppe105_HA2"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#Setup environment
rm(list = ls())
library("tidyverse")
library("zoo")
library("forecast")
library("ggplot2")
library("GGally")

#library("data.table")
```

```{r}
#Daten einlesen.
externals = read.csv2("externals10.csv")
services = read.csv2("output_services_8Players_v0010.csv")
```

## Daten fuer die Modellierung vorbereiten

### Aufgabe 1: OTD und IFR nach berechnen
1) Laden Sie die Datensaetze externals und services. Berechnen Sie ueber den gesamten Datensatz services, d.h. fuer jede durchgefuehrte Dienstleistung, den On‐Time‐Delivery (OTD) Status (d.h. 0 oder FALSE, wenn unpuenktlich; 1 oder TRUE wenn puenktlich) sowie die Item Fill Rate (IFR). Stellen Sie an‐ schliessend jeweils die Kennzahlen der durchschnittlichen OTD‐Rate und der durchschnittlichen Item Fill Rate als Kennzahl je Logistikdienstleister aggregiert dar. Geben Sie diese Werte in zwei Tabellen aus. Die Tabellen sollen einen einfachen Vergleich der LDL ermöglichen. Bewertungsrelevant: Output, Code.
Hinweis: Erneut bietet es sich an, eine Variable Periode dem Datensatz hinzu zu fuegen, welche aus Jahr und Monat besteht (im Format YYYYMM, z.B. Februar 2014 –> 201402)
```{r}
#OTD und IFR berechnen.
services$OTD = services$DaysScheduled >= services$DaysExecuted
services$IFR = services$QExecuted / services$QScheduled

#Durchschnittliche OTD‐Rate und durchschnittliche Item Fill Rate als Kennzahl je Logistikdienstleister aggregiert darstellen.
mean_OTD_vendor = services %>% aggregate(OTD ~ vendor, data = ., mean)
mean_IFR_vendor = services %>% aggregate(IFR ~ vendor, data = ., mean)

#Darstellung
mean_OTD_vendor = mean_OTD_vendor[order(-mean_OTD_vendor$OTD),]
mean_IFR_vendor = mean_IFR_vendor[order(-mean_IFR_vendor$IFR),]

# Auf die 4. Nachkommastelle runden
mean_OTD_vendor[2] = round(mean_OTD_vendor$OTD, 4) 
mean_IFR_vendor[2] = round(mean_IFR_vendor$IFR, 4)

# DataFrame anzeigen
mean_OTD_vendor
mean_IFR_vendor
```
```{r}
#Erstellen von Periode-Variable
services$Periode = sprintf("%02d%02d", services$Year, services$Month)
```


2) Erzeugen Sie ein neues Dataframe, welches die aggregierte IFR je Warehousing‐Logistikdienstleister enthaelt. Die IFR soll je LDL (nur Warehousing), Region und Periode (eine Periode = ein Monat eines einzelnen Jahres) aggregiert werden. Geben Sie anschliessend eine Tabelle aus, die den einfachen Vergleich der WH‐DL fuer die Periode 2020/12 in Japan ermoeglicht. Bewertungsrelevant: Output, Code.
```{r}
# IFR je LDL (nur Warehousing), Region und Periode (eine Periode = ein Monat eines einzelnen Jahres) aggregiert.
wdl = services[services$service == "Warehousing",] %>% aggregate(IFR ~ vendor+region+Periode, data = ., mean)

# Nur Japan und Periode 2020/12
wdl_japan_202012 = wdl[wdl$region == "Japan" & wdl$Periode == "202012",]

# IFR runden auf vierte Stelle
wdl_japan_202012[4] = round(wdl_japan_202012$IFR, 4)

# Darstellung
wdl_japan_202012[order(-wdl_japan_202012$IFR),]
```

3) Erzeugen Sie ein neues Dataframe, welches die aggregierte OTD je Shipping‐Logistikdienstleister enthaelt. Die OTD soll je LDL (nur Shipping), Region und Periode (eine Periode = ein Monat eines einzelnen Jahres) aggregiert werden. Geben Sie anschliessend eine Tabelle aus, die den einfachen Vergleich der Shipping‐DL fuer die Periode 2020/12 in Japan ermoeglicht. Bewertungsrelevant: Output, Code.
```{r}
# IFR je LDL (nur Warehousing), Region und Periode (eine Periode = ein Monat eines einzelnen Jahres) aggregiert.
sdl = services[services$service == "Shipping",] %>% aggregate(OTD ~ vendor+region+Periode, data = ., mean)

# Nur Japan und Periode 2020/12
sdl_japan_202012 = sdl[sdl$region == "Japan" & sdl$Periode == "202012",]

#OTD runden auf vierte Stelle
sdl_japan_202012[4] = round(sdl_japan_202012$OTD, 4)

# Darstellung 
sdl_japan_202012[order(-sdl_japan_202012$OTD),]
```

##Modellierung: Warehousing
4) Waehlen Sie den Warehousing‐DL “CPS Warehousing” aus. Vereinigen Sie das eben erzeugte DataFrame (genauer: Ein Subset dieses Dataframes bezueglich des gewaehlten Warehousing‐DL) mit den externen Faktoren der jeweiligen Periode und Region in einem neuen Dataframe. Zeigen Sie davon den Tabellenkopf. Bewertungsrelevant: Output.
Hinweis: In der Funktion merge() koennen mehrere ueberschneidende Spalten genutzt werden, indem dem “by =”‐Parameter ein Vektor der Spalten uebergeben wird. Ihnen steht frei, andere Funktionen zu verwenden.
```{r}
# Spalte Periode für externals erzeugen um mergen zu erleichtern.
externals$Periode = sprintf("%02d%02d", externals$Year, externals$Month)

# CPS Warehousing subset
cps_wh = services[services$vendor == "CPS Warehousing",]

# cps_wh und externals in neuem Dataframe auf Periode und Region mergen.
cps_wh_externals = merge(cps_wh, externals, by = c("region","Periode"))

# Output
cps_wh_externals %>% head()
```

5) Sie moechten sich eine Uebersicht zu der Korrelation zwischen den externen Faktoren und der IFR des Warehousing‐Dienstleister schaffen. Fuehren Sie dazu die folgenden Schritte aus:
(a) Geben Sie eine unsortierte Tabelle aus, in der die externen Effekte und deren Korrelation zur IFR abgebildet sind.
```{r}
correlations = cor(cps_wh_externals$IFR, cps_wh_externals[, c(21:42)]) %>% as.data.frame(.) %>% t(.)
colnames(correlations) <- c("Korrelation zu IFR")
correlations
```
(b) Geben Sie eine Tabelle aus,in der die 5 am starksten zur IFR korrelierenden externen Effekten und deren Korrelation zur IFR abgebildet sind.
```{r}
correlations_ordered = data.frame(Features = row.names(correlations), correlations)
rownames(correlations_ordered) <- NULL

# Korrelationen sind start wenn sie nahe 1 oder nahe -1 sind, daher müssen die Absoluten Werte genommen werden.
correlations_ordered$Korrelation.zu.IFR = abs(correlations_ordered$Korrelation.zu.IFR) 
correlations_ordered[order(-correlations_ordered$Korrelation.zu.IFR),] %>% head( ., 5)
```
(c) Erstellen Sie ein Korrelations‐Plot fuer diese 5 externen Faktoren. Bewertungsrelevant: Output.
```{r}
# Correlation Plot erzeugen 
ggpairs(cps_wh_externals[, c("AvgHealth", "InternetStability", "BusinessConfidence", "ParkingSpaceAvailability", "Congestion")], 
        
        # ohne Visualisierung des Fortschritts der Erstellung des plots
        progress = FALSE,
        
        # mit Visualisierung einer Glaettungslinie und Aenderung der Farbe der Punkte, damit Linie erkennbar
        lower = list(continuous = wrap("smooth_loess", colour = "steelblue1")))
```


6) Sie moechten nun eine Lineare Regression durchfuehren, um die IFR mit Hilfe der externen Effekte vorherzusagen. Um die Guete Ihrer Modelle vergleichen zu koennen, benoetigen Sie eine geeignete Baseline. Erzeugen Sie eine sinnvolle Baseline in dem DataFrame zu Ihrem gewaehlten Warehousing‐DL in einer Variable Baseline. Begruenden Sie Ihre Wahl. Geben Sie von dem DataFrame den Tabellenkopf aus. Geben Sie Sie nur die Spalten ‘Periode’, ‘Region’, ‘IFR’ und ‘Baseline’ aus. Bewertungsrelevant: Output, Begruendung.
```{r}
# Baseline ist durschnittlicher IFR vom Monat.
cps_wh_externals = cps_wh_externals %>% aggregate(IFR ~ Periode, data = ., mean) %>% merge(cps_wh_externals, ., by = c("Periode"))

# Spalte richtig benennen.
colnames(cps_wh_externals)[43] = "Baseline"

# Tabellenkopf ausgeben.
cps_wh_externals[, c("Periode", "region", "IFR.x", "Baseline")] %>% head()
```

*Aufgabe 6 zweiter Vorschlag*
```{r}
# Baseline ist durschnittlicher IFR vom Monat
Baseline = data.frame(aggregate(IFR ~ Periode, data = cps_wh_externals, mean))

# Spalte umbenennen
colnames(Baseline) = c("Periode", "BaselineIFR")

# Merge der Baseline Tabelle und alten DataFrame
cps_wh_externals_baseline = merge(Baseline, cps_wh_externals, by=c("Periode"))

# BaselineIFR und IFR auf vierte Nachkommastelle runden
cps_wh_externals_baseline[2] = round(cps_wh_externals_baseline$BaselineIFR, 4)
cps_wh_externals_baseline[17] = round(cps_wh_externals_baseline$IFR, 4)

# ‘Periode’, ‘Region’, ‘IFR’ und ‘Baseline’ anzeigen
head(cps_wh_externals_baseline[c(1, 3, 17, 2)])
```



7) Visualisieren Sie die Baseline Ihres gewaehlten LDL fuer den Zeitraum von 2016 bis 2020 sowie die IFR in der Region Shanghai. Bewertungsrelevant: Output.
```{r}
plot_data = cps_wh_externals[(cps_wh_externals$Year.x >= 2016 | cps_wh_externals$Year.x <= 2020) & cps_wh_externals$region == "Shangh",]
plot_data = plot_data[, c("Periode", "IFR.x", "Baseline")] %>% aggregate(. ~ Periode, data = ., mean)

ggplot(data = plot_data, aes(x = Periode, group=1)) + 
  geom_line(aes(y = IFR.x), colour="red") +
  geom_line(aes(y = Baseline), colour="green") +
  # Beschriftung von x-Achse um 90 Grad gedreht
  theme(axis.text.x = element_text(angle=90, vjust = 0.5)) + 
  xlab("Periode") + 
  ylab("IFR") +
  ggtitle(label = "CPS Warehousing",
              subtitle = "IFR and Baseline from 2016 to 2020")


baseline_plot_data = plot_data[, c("Periode", "Baseline")]
baseline_plot_data$type = "baseline"
colnames(baseline_plot_data)[2] = "data"
ifr_plot_data = plot_data[, c("Periode", "IFR.x")]
ifr_plot_data$type = "IFR"
colnames(ifr_plot_data)[2] = "data"
plot_final_data = rbind(baseline_plot_data, ifr_plot_data)

ggplot(data = plot_final_data, aes(x = Periode, y=data, group=1, colour = type)) + 
  geom_line() +
  theme(axis.text.x = element_text(angle=90, vjust = 0.5, hjust=2, size=10)) + 
  xlab("Period") + 
  ylab("IFR")
```

8) Bewerten Sie die Baseline fuer Ihren gewaehlten Warehousing‐Logistikdienstleister nach MAE und MAPE.Bewertungsrelevant: Output.
Hinweis: Es bietet sich an, die Werte der Bewertungen in einem Dataframe ‘evaluation’ zu speichern.
### TODO: Ueberpruefen, ob sMAPE hier richtig ist.
```{r}
# DataFrame erzeugen, dass bei auf die Beschreibung ("Model") leer bzw. 0 ist
evaluation = data.frame(Model = "Baseline",
                        MAE = numeric(1),
                        sMAPE = numeric(1))

# MAE berechnen
evaluation[evaluation$Model == "Baseline",]$MAE = 
mean(abs(cps_wh_externals_baseline$IFR - cps_wh_externals_baseline$BaselineIFR))

# sMAPE berechnen
evaluation[evaluation$Model == "Baseline",]$sMAPE = 
smape(cps_wh_externals_baseline$IFR, cps_wh_externals_baseline$BaselineIFR)

# MAE und sMAPE auf vierte Nachkommastelle runden
evaluation[2] = round(evaluation$MAE,4)
evaluation[3] = round(evaluation$sMAPE,4)

# DataFrame anzeigen
evaluation
```

9) Teilen Sie das Dataframe Ihres gewaehlten Warehousing‐Logistikdienstleisters in ein Trainings‐ (80%) und ein Test‐Set (20%) auf. Geben Sie von beiden den Tabellenkopf aus. Setzen Sie vorher den Seed 4141. Bewer‐ tungsrelevant: Code, Output.
*Gegenmassnahme zum Overfitting: Aufteilung in Trainings- & Test-Data Set*

###TODO: Ueberpruefen, wo genau der Unterschied liegt zwischen diesem Model und voherigen.
```{r}
# Einen zufaelligen Zustand herstellen (der jedoch kontrolliert erstellt wird und daher wiederholbar ist)
set.seed(4141)

# eine Zufallsaufwahl erstellen: Aus der Liste von Zahlen 1 bis Laenge von cps_wh_externals werden 80% gewaehlt
zufall = sample(1:nrow(cps_wh_externals), nrow(cps_wh_externals) * 0.8)

# Die Eintraege in der Zufallsauswahl gehen in das TrainingsSet
cps_wh_externalsTraining = cps_wh_externals[zufall, ]

# Die Eintraege nicht in der Zufallsauswahl gehen in das TestSet
cps_wh_externalsTest = cps_wh_externals[-zufall, ]

#Tabellenkopf ausgeben
head(cps_wh_externalsTest)
```

### Aufgabe 10: 
(1) Wenden Sie die Forward Selection Variante der Wrapper Methode an (siehe Vorlesung). 
D.h. erstellen Sie zunaechst alle uni‐variaten Modelle, bewerten Sie diese Modelle und waehlen Sie das Modell mit der besten Bewertung aus. 
(2) Erstellen Sie ‐ basierend auf dem besten Modell der ersten Iteration ‐ alle bi‐variaten Modelle (das Modell der vorherigen Wrapper‐Iteration wird jeweils um eine Variable erweitert), bewerten Sie diese Modelle und waehlen Sie das Modell mit der besten Bewertung aus. Fuehren Sie dies so lange fort, bis keine Verbesserung mehr erreicht wird. Nutzen Sie zur Modellierung die lineare Regression. 
Bewerten Sie die Modelle entsprechend nach MAE und MAPE sowie nach regressionsspezifischen Kennzahlen. 
Nutzen Sie nur die 5 externen Faktoren als Features, die Sie oben als am staerksten korrelierende externe Faktoren identifiziert haben. Kommentieren Sie Ihr Vorgehen zwischen den Iterationen. 
Bewertungsrelevant: Output, Vorgehen (einschliesslich Kommentare).
Hinweis: Tritt eine starke Multikollinearität (“strong multicollinearity”) auf, so koennen Sie alle Mod‐ ellierungen mit der entsprechenden Variablen‐Kombination unter Bezug auf diesen Hinweis auslassen (siehe Vorlesungsinhalte zu Korrelation).
*Fragen: Baseline DataFrame verwenden oder normale cps_wh_externals DataFrame?*
### (1.1) Modelle erstellen
```{r echo=FALSE}
# Modelle erstellen mit untransformierter unabhaengiger Variable
# Wir betrachten jeweils nur ein Merkmal (univariater Datenanalyse)
  m1_1 = lm(AvgHealth ~ Periode , data = cps_wh_externals)
  m1_2 = lm(InternetStability ~ Periode, data = cps_wh_externals)
  m1_3 = lm(BusinessConfidence ~ Periode, data = cps_wh_externals)
  m1_4 = lm(ParkingSpaceAvailability ~ Periode, data = cps_wh_externals)
  m1_5 = lm(Congestion ~ Periode, data = cps_wh_externals)

# Anzeigen der Modelle
  summary(m1_1)
  summary(m1_2)
  summary(m1_3)
  summary(m1_4)
  summary(m1_5)
```


### (1.2) Bewertung des besten Modells
*Quelle: http://www.evanlray.com/stat140_f2018/materials/20181112_residuals/20181112_residual_standard_error_R_squared.pdf*
(1) Residuenplots 
```{r}
#Residuenplot Modell 1 (Variable AvgHealth)
ggplot(data = NULL, aes(x = m1_1$model$AvgHealth, y = m1_1$residuals)) + 
  geom_point() + 
  geom_smooth(se = FALSE, method = loess)

#Residuenplot Modell 2 (Variable InternetStability)
ggplot(data = NULL, aes(x = m1_2$model$InternetStability, y = m1_2$residuals)) + 
  geom_point() + 
  geom_smooth(se = FALSE, method = loess)

#Residuenplot Modell 3 (Variable BusinessConfidence)
ggplot(data = NULL, aes(x = m1_3$model$BusinessConfidence, y = m1_3$residuals)) + 
  geom_point() + 
  geom_smooth(se = FALSE, method = loess)

#Residuenplot Modell 4 (Variable ParkingSpaceAvailability)
ggplot(data = NULL, aes(x = m1_4$model$ParkingSpaceAvailability, y = m1_4$residuals)) + 
  geom_point() + 
  geom_smooth(se = FALSE, method = loess)

#Residuenplot Modell 5 (Variable Congestion)
ggplot(data = NULL, aes(x = m1_5$model$Congestion, y = m1_5$residuals)) + 
  geom_point() + 
  geom_smooth(se = FALSE, method = loess)
```
**Bewertung und Auswahl Begruendung:** 
Wir nehmen ParkingSpaceAvailability, da das Residual standard error bei 0.01253
liegt und somit die hoechste Wahrscheinlichkeit im Vergleich zu den anderen
Modellen hat eine korrekte Vorhersage zu machen.



### (3) Fehlerkennzahlen berechnen
*TODO*
```{r}
# Data Frame erweitern
evaluation1_1 = rbind(evaluation1_1, data.frame(Model = "m1_1",
                                     MAE = numeric(1),
                                     sMAPE = numeric(1)))

# MAE berechnen
evaluation1_1[evaluation1_1$m1_1 == "Model2",]$MAE = 
  mean(abs(m1_1$residuals))

# sMAPE berechnen
evaluation1_1[evaluation1_1$m1_1 == "Model2",]$sMAPE = 
  smape(m1_1$model$ , m1_1$fitted.values)

### Auf Aufgabe 10 Lösungen. Muss noch angepasst werden.
# MAE berechnen
evaluation[evaluation$Model == "Model2",]$MAE = mean(abs(model2$residuals))

# sMAPE berechnen
evaluation[evaluation$Model == "Model2",]$sMAPE = smape(model2$model$Fehlmenge, model2$fitted.values)


# Fehler anzeigen
evaluation
```
**Bewertung und Auswahl Begruendung:** 
Wir nehmen ParkingSpaceAvailability, da das Residual standard error am kleinsten
ist, da es im Vergleich zu den anderen Modellen bei 0.01253 also nah an 0 liegt.
ParkingSpaceAvailability hat somit die hoechste Wahrscheinlichkeit eine korrekte 
Vorhersage zu machen.

### (2) um eine Variable erweitern
```{r}

```
### (2.2) Modell bewerten
```{r}

```

### (2.3) Bestes Modell auswaehlen
```{r}

```

### Fehlerkennzahlen berechnen
```{r}
# Data Frame erweitern
evaluation1_4 = rbind(evaluation1_4, data.frame(Model = "m1_4",
                                     MAE = numeric(1),
                                     sMAPE = numeric(1)))

# MAE berechnen
evaluation1_4[evaluation1_4$Model == "Model1_4",]$MAE = mean(abs(model1_4$residuals))

# sMAPE berechnen
evaluation[evaluation$Model == "Model1_4",]$sMAPE = smape(model1_4$model$Fehlmenge, model2$fitted.values)


# Fehler anzeigen
evaluation
```
**Auswahl Begruendung:**
BEISPIEL: Die Auswahl des besseren Modells ist hier nicht eindeutig. Das Modell2 liegt in MAE und MSE vorn  und Modell1 beim sMAPE. Eine Unterschiedliche Ausrichtung von MAE und sMAPE spricht dafuer, dass der sMAPE aufgrund von Null-Werten verzerrt ist. Entsprechend wird aufgrund des MAE, MSE und des Residuenplots weiter verfahren.






11) Bewerten Sie ihr Modell quantitativ im Vergleich mit der Baseline. Bewertungsrelevant: Output, Kommentar.
```{r}

```

12) Ihre Chefin kommt auf der Firmenfeier zu Ihnen und schlaegt Ihnen eine Wette vor. Sie sagt: “Ich wette mit Ihnen um 100 Euro, dass die IFR des oben betrachteten WH‐DL im naechsten Monat (Januar 2021) in allen Regionen ueber 0.85 sein wird.” Sollten Sie die Wette eingehen? Bewertungsrelevant: Output, Kommentar.
```{r}

```

##Entscheidung

13) IhrRegressionsmodellsollimkommendenJahrimplementiertundlangfristigindieUnternehmensprozessein‐ tegriert werden. Beschreiben Sie, welche Nutzer und Prozesse davon profitieren koennten und in welcher Form die Loesung bereitgestellt werden koennte. Nehmen Sie ausserdem ausfuehrlich zur Phase der Datenbeschaf‐ fung Stellung. Bewertungsrelevant: Kommentar.
```{r}

```




