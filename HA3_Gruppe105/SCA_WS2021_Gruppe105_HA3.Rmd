---
title: "SCA_WS2021_Gruppe105_HA2"
output: html_document
---
*Wilke Update*
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#Setup environment
rm(list = ls())
library("tidyverse")
library("zoo")
library("forecast")
library("ggplot2")
library("Metrics")
```

1) Laden Sie die Datensaetze externals und services. Berechnen Sie ueber den gesamten Datensatz services, d.h. fuer jede durchgefuehrte Dienstleistung, den On‐Time‐Delivery (OTD) Status (d.h. 0 oder FALSE, wenn unpuenktlich; 1 oder TRUE wenn puenktlich) sowie die Item Fill Rate (IFR). Stellen Sie an‐ schliessend jeweils die Kennzahlen der durchschnittlichen OTD‐Rate und der durchschnittlichen Item Fill Rate als Kennzahl je Logistikdienstleister aggregiert dar. Geben Sie diese Werte in zwei Tabellen aus. Die Tabellen sollen einen einfachen Vergleich der LDL ermöglichen. Bewertungsrelevant: Output, Code.
Hinweis: Erneut bietet es sich an, eine Variable Periode dem Datensatz hinzu zu fuegen, welche aus Jahr und Monat besteht (im Format YYYYMM, z.B. Februar 2014 –> 201402)
```{r}
#Daten einlesen.
externals = read.csv2("externals10.csv")
services = read.csv2("output_services_8Players_v0010.csv")

#OTD und IFR berechnen.
services$OTD = services$DaysScheduled >= services$DaysExecuted
services$IFR = services$QExecuted / services$QScheduled

#Durchschnittliche OTD‐Rate und durchschnittliche Item Fill Rate als Kennzahl je Logistikdienstleister aggregiert darstellen.
mean_OTD_vendor = services %>% aggregate(OTD ~ vendor, data = ., mean)
mean_IFR_vendor = services %>% aggregate(IFR ~ vendor, data = ., mean)

#Darstellung
mean_OTD_vendor[order(-mean_OTD_vendor$OTD),]
mean_IFR_vendor[order(-mean_IFR_vendor$IFR),]

#Erstellen von Periode-Variable
services$Periode = sprintf("%02d%02d", services$Year, services$Month)

```

2) Erzeugen Sie ein neues Dataframe, welches die aggregierte IFR je Warehousing‐Logistikdienstleister enthaelt. Die IFR soll je LDL (nur Warehousing), Region und Periode (eine Periode = ein Monat eines einzelnen Jahres) aggregiert werden. Geben Sie anschliessend eine Tabelle aus, die den einfachen Vergleich der WH‐DL fuer die Periode 2020/12 in Japan ermoeglicht. Bewertungsrelevant: Output, Code.
```{r}
# IFR je LDL (nur Warehousing), Region und Periode (eine Periode = ein Monat eines einzelnen Jahres) aggregiert.
wdl = services[services$service == "Warehousing",] %>% aggregate(IFR ~ vendor+region+Periode, data = ., mean)

# Nur Japan und Periode 2020/12
wdl_japan_202012 = wdl[wdl$region == "Japan" & wdl$Periode == "202012",]

# Darstellung
wdl_japan_202012[order(-wdl_japan_202012$IFR),]

#TODO IFR runden auf vierte Stelle
```

3) Erzeugen Sie ein neues Dataframe, welches die aggregierte OTD je Shipping‐Logistikdienstleister enthaelt. Die OTD soll je LDL (nur Shipping), Region und Periode (eine Periode = ein Monat eines einzelnen Jahres) aggregiert werden. Geben Sie anschliessend eine Tabelle aus, die den einfachen Vergleich der Shipping‐DL fuer die Periode 2020/12 in Japan ermoeglicht. Bewertungsrelevant: Output, Code.
```{r}
# OTD je LDL (nur Warehousing), Region und Periode (eine Periode = ein Monat eines einzelnen Jahres) aggregiert.
sdl = services[services$service == "Shipping",] %>% aggregate(OTD ~ vendor+region+Periode, data = ., mean)

# Nur Japan und Periode 2020/12
sdl_japan_202012 = sdl[sdl$region == "Japan" & sdl$Periode == "202012",]

# Darstellung 
sdl_japan_202012[order(-sdl_japan_202012$OTD),]

#TODO OTD runden auf vierte Stelle
```

##Modellierung: Warehousing
4) Waehlen Sie den Warehousing‐DL “CPS Warehousing” aus. Vereinigen Sie das eben erzeugte DataFrame (genauer: Ein Subset dieses Dataframes bezueglich des gewaehlten Warehousing‐DL) mit den externen Faktoren der jeweiligen Periode und Region in einem neuen Dataframe. Zeigen Sie davon den Tabellenkopf. Bewertungsrelevant: Output.
Hinweis: In der Funktion merge() koennen mehrere ueberschneidende Spalten genutzt werden, indem dem “by =”‐Parameter ein Vektor der Spalten uebergeben wird. Ihnen steht frei, andere Funktionen zu verwenden.
```{r}
# Spalte Periode für externals erzeugen um mergen zu erleichtern.
externals$Periode = sprintf("%02d%02d", externals$Year, externals$Month)

# CPS Warehousing subset
cps_wh = services[services$vendor == "CPS Warehousing",]

# cps_wh und externals in neuem Dataframe auf Periode und Region mergen.
cps_wh_externals = merge(cps_wh, externals, by = c("region","Periode"))

# Output
cps_wh_externals %>% head()
```

5) Sie moechten sich eine Uebersicht zu der Korrelation zwischen den externen Faktoren und der IFR des Warehousing‐Dienstleister schaffen. Fuehren Sie dazu die folgenden Schritte aus:
(a) Geben Sie eine unsortierte Tabelle aus, in der die externen Effekte und deren Korrelation zur IFR abgebildet sind.
```{r}
correlations = cor(cps_wh_externals$IFR, cps_wh_externals[, c(21:42)]) %>% as.data.frame(.) %>% t(.)
colnames(correlations) <- c("Korrelation zu IFR")
correlations
```
(b) Geben Sie eine Tabelle aus,in der die 5 am starksten zur IFR korrelierenden externen Effekten und deren Korrelation zur IFR abgebildet sind.
```{r}
correlations_ordered = data.frame(Features = row.names(correlations), correlations)
rownames(correlations_ordered) <- NULL

# Korrelationen sind start wenn sie nahe 1 oder nahe -1 sind, daher müssen die Absoluten Werte genommen werden.
correlations_ordered$Korrelation.zu.IFR = abs(correlations_ordered$Korrelation.zu.IFR) 
correlations_ordered[order(-correlations_ordered$Korrelation.zu.IFR),] %>% head( ., 5)
```
(c) Erstellen Sie ein Korrelations‐Plot fuer diese 5 externen Faktoren. Bewertungsrelevant: Output.
```{r eval = FALSE}
# Correlation Plot erzeugen 
ggpairs(cps_wh_externals[, c("IFR", "AvgHealth", "InternetStability", "BusinessConfidence", "ParkingSpaceAvailability", "Congestion")], 
        
        # ohne Visualisierung des Fortschritts der Erstellung des plots
        progress = FALSE,
        
        # mit Visualisierung einer Glaettungslinie und Aenderung der Farbe der Punkte, damit Linie erkennbar
        lower = list(continuous = wrap("smooth_loess", colour = "steelblue1")))

# TODO Remove eval = false
```

6) Sie moechten nun eine Lineare Regression durchfuehren, um die IFR mit Hilfe der externen Effekte vorherzusagen. Um die Guete Ihrer Modelle vergleichen zu koennen, benoetigen Sie eine geeignete Baseline. Erzeugen Sie eine sinnvolle Baseline in dem DataFrame zu Ihrem gewaehlten Warehousing‐DL in einer Variable Baseline. Begruenden Sie Ihre Wahl. Geben Sie von dem DataFrame den Tabellenkopf aus. Geben Sie Sie nur die Spalten ‘Periode’, ‘Region’, ‘IFR’ und ‘Baseline’ aus. Bewertungsrelevant: Output, Begruendung.
```{r}
# Baseline ist durschnittlicher IFR vom Monat.
cps_wh_externals = cps_wh_externals %>% aggregate(IFR ~ Periode, data = ., mean) %>% merge(cps_wh_externals, ., by = c("Periode"))

# Entferne hinzugefügtes .X und .y von Spaltennamen
colnames(cps_wh_externals) = gsub('\\.x','',names(cps_wh_externals))
colnames(cps_wh_externals) = gsub('\\.y','',names(cps_wh_externals))

# Spalten richtig benennen.
colnames(cps_wh_externals)[2] = "Region"
colnames(cps_wh_externals)[43] = "Baseline"

# Tabellenkopf ausgeben.
cps_wh_externals[, c("Periode", "Region", "IFR", "Baseline")] %>% head()

#TODO Begründung fehlt
```

7) Visualisieren Sie die Baseline Ihres gewaehlten LDL fuer den Zeitraum von 2016 bis 2020 sowie die IFR in der Region Shanghai. Bewertungsrelevant: Output.
```{r}
plot_data = cps_wh_externals[(cps_wh_externals$Year >= 2016 | cps_wh_externals$Year <= 2020) & cps_wh_externals$Region == "Shangh",]
plot_data = plot_data[, c("Periode", "IFR", "Baseline")] %>% aggregate(. ~ Periode, data = ., mean)

baseline_plot_data = plot_data[, c("Periode", "Baseline")]
baseline_plot_data$type = "Baseline"
colnames(baseline_plot_data)[2] = "data"

ifr_plot_data = plot_data[, c("Periode", "IFR")]
ifr_plot_data$type = "IFR"
colnames(ifr_plot_data)[2] = "data"

plot_final_data = rbind(baseline_plot_data, ifr_plot_data)
plot_final_data$Periode = as.yearmon(plot_final_data$Periode, "%Y%m")

ggplot(data = plot_final_data, aes(x = Periode, y=data, colour = type)) + 
  geom_line() +
  theme(axis.text.x = element_text(angle=90, vjust = 0.5, hjust=2, size=6), 
    legend.position = c(.16, .95),
    legend.justification = c("right", "top"),
    legend.box.just = "right",
    legend.margin = margin(6, 6, 6, 6)
   ) + 
  xlab("Period") + 
  ylab("IFR") +
  ggtitle(label = "CPS Warehousing IFR and Baseline from 2016 to 2020")
# Clean up
rm(plot_data, baseline_plot_data, ifr_plot_data, plot_final_data)
```

8) Bewerten Sie die Baseline fuer Ihren gewaehlten Warehousing‐Logistikdienstleister nach MAE und MAPE.Bewertungsrelevant: Output.
Hinweis: Es bietet sich an, die Werte der Bewertungen in einem Dataframe ‘evaluation’ zu speichern.
```{r}
# DataFrame erzeugen, dass bei auf die Beschreibung ("Model") leer bzw. 0 ist
evaluation = data.frame(Model = "Baseline",
                        MAE = numeric(1),
                        sMAPE = numeric(1))

# MAE berechnen
evaluation[evaluation$Model == "Baseline",]$MAE = mean(abs(cps_wh_externals$IFR - cps_wh_externals$Baseline))

# sMAPE berechnen
evaluation[evaluation$Model == "Baseline",]$sMAPE = smape(cps_wh_externals$IFR, cps_wh_externals$Baseline)

# MAE und sMAPE auf vierte Nachkommastelle runden
evaluation[2] = round(evaluation$MAE,4)
evaluation[3] = round(evaluation$sMAPE,4)

# DataFrame anzeigen
evaluation

```

9) Teilen Sie das Dataframe Ihres gewaehlten Warehousing‐Logistikdienstleisters in ein Trainings‐ (80%) und ein Test‐Set (20%) auf. Geben Sie von beiden den Tabellenkopf aus. Setzen Sie vorher den Seed 4141. Bewer‐ tungsrelevant: Code, Output.
```{r}
# Erzeuge iterative Zahlenreihe statt Periode
cps_wh_externals <- transform(cps_wh_externals,PeriodeNumber=as.numeric(factor(Periode)))

# Einen zufaelligen Zustand herstellen (der jedoch kontrolliert erstellt wird und daher wiederholbar ist)
set.seed(4141)

# eine Zufallsaufwahl erstellen: Aus der Liste von Zahlen 1 bis Laenge von cps_wh_externals werden 80% gewaehlt
zufall = sample(1:nrow(cps_wh_externals), nrow(cps_wh_externals) * 0.8)

# Die Eintraege in der Zufallsauswahl gehen in das TrainingsSet
cps_wh_externalsTraining = cps_wh_externals[zufall, ]

# Die Eintraege nicht in der Zufallsauswahl gehen in das TestSet
cps_wh_externalsTest = cps_wh_externals[-zufall, ]

#Tabellenkopf ausgeben
head(cps_wh_externalsTest)
```

10) Wenden Sie die Forward Selection Variante der Wrapper Methode an (siehe Vorlesung). D.h. erstellen Sie zunaechst alle uni‐variaten Modelle, bewerten Sie diese Modelle und waehlen Sie das Modell mit der besten Bewertung aus. Erstellen Sie ‐ basierend auf dem besten Modell der ersten Iteration ‐ alle bi‐variaten Mod‐ elle (das Modell der vorherigen Wrapper‐Iteration wird jeweils um eine Variable erweitert), bewerten Sie diese Modelle und waehlen Sie das Modell mit der besten Bewertung aus. Fuehren Sie dies so lange fort, bis keine Verbesserung mehr erreicht wird. Nutzen Sie zur Modellierung die lineare Regression. Bewerten Sie die Modelle entsprechend nach MAE und MAPE sowie nach regressionsspezifischen Kennzahlen. Nutzen Sie nur die 5 externen Faktoren als Features, die Sie oben als am staerksten korrelierende externe Faktoren identifiziert haben. Kommentieren Sie Ihr Vorgehen zwischen den Iterationen. Bewertungsrelevant: Output, Vorgehen (einschliesslich Kommentare).

Hinweis: Tritt eine starke Multikollinearität (“strong multicollinearity”) auf, so koennen Sie alle Mod‐ ellierungen mit der entsprechenden Variablen‐Kombination unter Bezug auf diesen Hinweis auslassen (siehe Vorlesungsinhalte zu Korrelation).
```{r}

#Aufg. 10: Nur sMape und MAE und Fehlerkennzahlen
#Aufg. 11:  Nur nach sMape und MAE

# Spalte für R und R**2 hinzufügen bei evaluation df hinzufügen.
evaluation$R = NA %>% as.numeric(.) 
evaluation$R2 = NA %>% as.numeric(.)

# Funktion um MAE und sMAPE für Modelle auszurechnen.  
model_bewertungsfunktion <- function(evaluation, model) {
          # Modelname
          modelname = deparse(substitute(model))
          
          # DF erweitern.
          evaluation = rbind(evaluation, data.frame(Model = 
                               modelname, MAE = numeric(1), sMAPE = numeric(1), R  = as.numeric(NA), R2  = as.numeric(NA))) 
          
          # MAE berechnen.
          evaluation[evaluation$Model == modelname,]$MAE = mean(abs(model$residuals)) #%>% round(.,4)
          
          # sMAPE berechnen.
          evaluation[evaluation$Model == modelname,]$sMAPE = smape(model$model[,1], model$fitted.values) #%>% round(.,4)
          
          # R berechnen.
          #evaluation[evaluation$Model == modelname,]$sMAPE = smape(model$model[,1], model$fitted.values) %>% round(.,4)
          
          # R**2 berechnen.
          #evaluation[evaluation$Model == modelname,]$sMAPE = smape(model$model[,1], model$fitted.values) %>% round(.,4)
          
          evaluation %>% unique() %>% return()
}

# 1. Iteration
# Modelle erstellen mit untransformierter unabhaengiger Variable
# Wir betrachten jeweils nur ein Merkmal (univariater Datenanalyse)

cps_wh_externalsTraining$Periode = as.factor(cps_wh_externalsTraining$Periode)

m1_1 = lm(IFR ~ PeriodeNumber + AvgHealth, data = cps_wh_externalsTraining)
m1_2 = lm(IFR ~ PeriodeNumber + InternetStability, data = cps_wh_externalsTraining)
m1_3 = lm(IFR ~ PeriodeNumber + BusinessConfidence, data = cps_wh_externalsTraining)
m1_4 = lm(IFR ~ PeriodeNumber + ParkingSpaceAvailability, data = cps_wh_externalsTraining)
m1_5 = lm(IFR ~ PeriodeNumber + Congestion, data = cps_wh_externalsTraining)

evaluation = model_bewertungsfunktion(evaluation,m1_1)
evaluation = model_bewertungsfunktion(evaluation,m1_2)
evaluation = model_bewertungsfunktion(evaluation,m1_3)
evaluation = model_bewertungsfunktion(evaluation,m1_4)
evaluation = model_bewertungsfunktion(evaluation,m1_5)
#evaluation
summary(m1_1)

# Begruendung: m1_1 hat niedrigstes MAE und sMAPE, daher fahren wir mit 
# diesem Modell fort. Residual standard error von m1_1 ist zudem das leinste.
```

```{r}
# 2. Iteration
m1_1_2 = lm(IFR ~ PeriodeNumber + AvgHealth + InternetStability, data = cps_wh_externalsTraining)
m1_1_3 = lm(IFR ~ PeriodeNumber + AvgHealth + BusinessConfidence, data = cps_wh_externalsTraining)
m1_1_4 = lm(IFR ~ PeriodeNumber + AvgHealth + ParkingSpaceAvailability, data = cps_wh_externalsTraining)
m1_1_5 = lm(IFR ~ PeriodeNumber + AvgHealth + Congestion, data = cps_wh_externalsTraining)

evaluation = model_bewertungsfunktion(evaluation,m1_1_2)
evaluation = model_bewertungsfunktion(evaluation,m1_1_3)
evaluation = model_bewertungsfunktion(evaluation,m1_1_4)
evaluation = model_bewertungsfunktion(evaluation,m1_1_5)
# evaluation
# m1_1_4 hat niedrigstes MAE und sMAPE, daher fahren wir mit diesem Modell fort.
```

```{r}
# 3. Iteration
m1_1_4_2 = lm(IFR ~ PeriodeNumber + AvgHealth + ParkingSpaceAvailability + InternetStability, data = cps_wh_externalsTraining)
m1_1_4_3 = lm(IFR ~ PeriodeNumber + AvgHealth + ParkingSpaceAvailability + BusinessConfidence, data = cps_wh_externalsTraining)
m1_1_4_5 = lm(IFR ~ PeriodeNumber + AvgHealth + ParkingSpaceAvailability + Congestion, data = cps_wh_externalsTraining)

evaluation = model_bewertungsfunktion(evaluation,m1_1_4_2)
evaluation = model_bewertungsfunktion(evaluation,m1_1_4_3)
evaluation = model_bewertungsfunktion(evaluation,m1_1_4_5)
# evaluation
# m1_1_4_2 hat niedrigstes MAE und sMAPE, daher fahren wir mit diesem Modell fort.
```

```{r}
 # 4. Iteration
m1_1_4_2_3 = lm(IFR ~ PeriodeNumber + AvgHealth + ParkingSpaceAvailability + InternetStability + BusinessConfidence, data = cps_wh_externalsTraining)
m1_1_4_2_5 = lm(IFR ~ PeriodeNumber + AvgHealth + ParkingSpaceAvailability + InternetStability + Congestion, data = cps_wh_externalsTraining)

evaluation = model_bewertungsfunktion(evaluation,m1_1_4_2_3)
evaluation = model_bewertungsfunktion(evaluation,m1_1_4_2_5)
# evaluation
# m1_1_4_2_3 und m1_1_4_2_5 haben den selben MAE und sMAPE wert, daher spielt es keine Rolle welchen wir nehmen. Wir fahren mit m1_1_4_2_3 fort.
```

```{r}
# 5. Iteration
m1_1_4_2_3_5 = lm(IFR ~ PeriodeNumber + AvgHealth + ParkingSpaceAvailability + InternetStability + BusinessConfidence + Congestion, data = cps_wh_externalsTraining)

evaluation = model_bewertungsfunktion(evaluation,m1_1_4_2_3_5)
evaluation
# m1_1_4_2_3_5 hat keine Verbesserung gebracht, daher gehen wir zurück zu m1_1_4_2_3 und bleiben dabei.
```

# Wir vergleichen Trainings- und Test-Daten und bewerten die zwei Modelle.
# Dabei ueberpruefen wir das endgueltige Modell am Ende auf Overfitting mit den Test‐Daten.
# Wir berechnen die Fehlerkennzahlen fuer TestSet. Dies verlangt, dass fuer das 
# Test-Set Vorhersagen erstellt werden mit der `predict()` Funktion
```{r}
# Test-Daten
pred1 = lm(IFR ~ Periode + AvgHealth + ParkingSpaceAvailability + 
        InternetStability + Congestion, 
        data = cps_wh_externalsTest)

# Vorhersage mit Test-Daten treffen
pred1 = predict(pred1, cps_wh_externalsTest)  

# Data Frame erweitern
evaluationNeu = rbind(data.frame(Model = c("pred1_test"),
                                          MAE = numeric(2),
                                          sMAPE = numeric(2)))

# MAE berechnen
evaluationNeu[evaluationNeu$Model == "pred1_test", ]$MAE = 
                                    mean(abs(cps_wh_externalsTest$IFR - pred1))

# sMAPE berechnen
evaluationNeu[evaluationNeu$Model == "pred1_test", ]$sMAPE = 
                                    smape(cps_wh_externalsTest$IFR, pred1)

# Runden und anzeigen
evaluationNeu[2] = round(evaluationNeu$MAE, 4)
evaluationNeu[3] = round(evaluationNeu$sMAPE, 4)
head(evaluationNeu,2)

# Kommentar: Ein Overfitting ist hierbei nicht zu finden.
```

11) Bewerten Sie ihr Modell quantitativ im Vergleich mit der Baseline. Bewertungsrelevant: Output, Kommentar.
```{r}
# Bewertung von Baseline Modell
# DataFrame erzeugen
evaluation = data.frame(Model = "Baseline",
                        MAE = numeric(1),
                        sMAPE = numeric(1))

# MAE von Baseline Modell berechnen
evaluation[evaluation$Model == "Baseline",]$MAE = 
  mean(abs(cps_wh_externals$IFR - cps_wh_externals$Baseline))

# sMAPE von Baseline Modell berechnen
evaluation[evaluation$Model == "Baseline",]$sMAPE = 
  smape(cps_wh_externals$IFR, cps_wh_externals$Baseline)


# Bewertung von Modell m1_1_4_2_3 aus der 4. Iteration
evaluation = model_bewertungsfunktion(evaluation, m1_1_4_2_3)

# Fehler der Modelle auf die vierte Nachkommastelle runden
evaluation[2] = round(evaluation$MAE, 4)
evaluation[3] = round(evaluation$sMAPE, 4)

# Vergleich der Fehler beider Modelle anzeigen
evaluation
```
### TODO: Vergleich von Baseline und best model R und adjR
Kommentar: Es gab eine Verbesserung im Modell	m1_1_4_2_3 im Vergleich zur 
Baseline, da MAE und sMAPE kleiner sind als die Fehlerwerte vom Baseline Modell.




12) Ihre Chefin kommt auf der Firmenfeier zu Ihnen und schlaegt Ihnen eine Wette vor. Sie sagt: “Ich wette mit Ihnen um 100 Euro, dass die IFR des oben betrachteten WH‐DL im naechsten Monat (Januar 2021) in allen Regionen ueber 0.85 sein wird.” Sollten Sie die Wette eingehen? Bewertungsrelevant: Output, Kommentar.
# TODO zusammenfassung von region (und Periode) muessen rein
```{r}
#TODO
# Da wir 2021/01 die Werte berechnen wollen, setzen wir fuer unsere Vorhersage die historischen Januars von 2016 bis 2020 voraus
cps_wh_externals = cps_wh_externals[cps_wh_externals$Month == "1",] 

# Modell erstellen fuer alle Regionen auf Basis des besten Modells m1_1_4_2_3 und den Baseline Werten
predictModel = lm(IFR ~ Periode, data = cps_wh_externals)
predictModelBaseline = lm(Baseline ~ Periode, data = cps_wh_externals)

# predict(model, data)
predictDFBaseline = 
  data.frame(predict(predictModelBaseline, data=cps_wh_externals)) # cps_wh_externals$Region, cps_wh_externals$Periode) %>% unique(.) #%>% aggregate(IFR ~ Periode, data = ., mean)

predictDF_bestmodel = 
  data.frame(predict(m1_1_4_2_3, data=cps_wh_externals))

# Spalte umbenennen
colnames(predictDFBaseline)  = "Vorhersage Baseline"
colnames(predictDF_bestmodel)  = "Vorhersage Bestes Modell"

# Runden
predictDFBaseline[1] = round(predictDFBaseline$Vorhersage, 4)
predictDF_bestmodel[1] = round(predictDF_bestmodel$Vorhersage, 4)

#head(predictDF)
head(predictDFBaseline)
head(predictDF_bestmodel)
```
Kommentar zu Aufgabe 12: Wir nehmen alle historischen Werte von Januar, um den Januar 2021 zu bestimmen. Wir gehen die Wette ein, da die Vorhersage ueber 0.85 liegt. Dafuer haben wir das beste Modell m1_1_4_2_3 und die Baseline Werte zur Grunde gelegt und ueberprueft, ob die Vorhersagewerte ueber 0.85 liegen. In diesem Fall zeigt uns das Baseline Modell, dass unsere Vorhersagewerte ueber 0.85 und beim Modell m1_1_4_2_3 auch mehrheitlich ueber 0.85.




##Entscheidung
Antwort zu Aufgabe 13:
*Nutzer*: Da unser Regressionsmodell im kommenden Jahr langfristig in die 
Unternehmensprozesse implementiert werden soll, stellt sich die Frage, 
welche Nutzer und welche Prozesse vom Regressionsmodell profitieren koennen, 
und in welcher Form die Loesung bereitgestellt werden soll. 
Hierbei nehmen wir an, dass die Geschaeftsfuehrung einen Vorrang auf Informationsbereitstellung hat, da diese Stakeholder wichtige und 
langfristige Entscheidungen im Unternehmen treffen werden. 
Diese Entscheidungen koennen sie mit Hilfe des Regressionsmodells treffen, da 
das Modell eine Uebersicht ueber den Einfluss der Externen Effekte auf die 
Leistung der Logistikdienstleister darstellt. Dabei wurden fuenf externe 
Effekte identifiziert, die vergleichsweise den groeßten Einfluss auf die Logistikdienstleister haben.Weitere Nutzer koennen neben der Geschaeftsfuehrung 
auch die Abteilungen der Logistik sowie Finanz-Abteilung sein,da das Modell 
wichtige Logistik-Kennzahlen wie das Iten Fill Rate (IFR) abbildet.
*Prozesse*: Anhand des Regressionsmodells kann beispielsweise die Logistik-
Abteilung Abschaetzungen machen, wie die Leistungen der Logistikdienstleister in 
einem bestimmten Zeitraum war und durch welche externen Faktoren diese Leistung beeinflusst wurde. Hierbei kann die Logistik-Abteilung beispielsweise die Lieferprozesse sowie SLAs durch die Erkenntnisgewinnung besser steuern. Wir 
haben diese fuenf externen Faktoren: Periode, AvgHealth, 
ParkingSpaceAvailability, InternetStability und Congestion in unserem 
Modell abgebildet.
*Loesungsbereitstellung*: Die Loesungsbereitstellung kann in verschiedenen 
Formen erfolgen. Da unser Modell auf R basiert, koennen wir Visualisierungs-
software, wie z.B. MicroStrategy oder Microsoft Power BI, verwenden unter der
Bedingung, dass die Lizensen und der Zugang im Unternehmen vorhanden sind.
Andernfalls kann die Loesungsbereitstellung auf ueber Excel oder R-Studio 
erfolgen. Von PDF oder Papier Präsentation des Modells raten wir ab.

*Stellungnahme zur Datenbeschaffung*:
Bei der Datenbeschaffung gehen wir entlang der folgenden Phasen vor.
1. Unternehmen verstehen / Zielsetzung: 
Zuerst muessen wir das Unternehmen besser verstehen, um herauszufinden, welches 
Ziel wir verfolgen. Bei der Distribution von “Limonalytics” wollen wir fuer die naechsten Monate im Voraus planen und ein Modell erstellen, um deren Leistung 
auf Basis von externen Effekten abzuschaetzen. Das Ziel ist hierbei anhand eines Regressionsmodells zukuenftige Entscheidungen fundiert und effizient abzuleiten.
Hierbei schauen wir uns die externen Effekte der letzten 60 Monate (2016‐2020)
an sowie die Vorhersage fuer die kommenden 12 Monate (2021).
2. Daten sammeln: Da wir zuerst eine große Datensammlung benoetigen, um sie
weiter zu verarbeiten, fokussieren wir uns auf die Logistikzentralen an den
jeweiligen Standorten, die uns Daten zu den Logistik-Dienstleistungen beschaffen 
koennen. Andernfalls wuerden wir auf unseren lokalen Servern Durchsuchungen 
bestreben, Befragungen bei der Logistikabteilung durchfuehren, um mehr Daten
zu externen Faktoren sammeln zu koennen oder uns an externe Datenquellen wie 
z.B. Statista, wenden.
3. Daten-Analyse: Bei der Datenbeschaffung ist es wichtig die Daten immer wieder
zu analysieren, um die Datenqualitaet zu erhoehen und falsche Vorhersagen zu vermeiden. Nach der Datenanalyse kommt im naechsten Schritt die Datenbereinigung sowie Datentransformation, um unseren aktuellen Unternehmenszustand sowie 
Vorhersage so praezise wie moeglich abzubilden.
4. Kennzahlen festlegen: Um weitere moeglichen relevanten Daten zu beschaffen,
wuerden wir als naechstes Kennzahlen festlegen. 
Der Zeitraum der Datensaetze ist bekannt und liegt zwischen 2016 und 2021.
Da Logistikdienstleistungen nicht immer mit Daten von externen Faktoren zu-
sammengefasst sind, wuerden wir DL und externen Faktoren basierend auf den
Perioden zusammenfassen. Je nach Ziel beschraenken wir uns auf bestimmte 
Regionen und Dienstleister. 
Da wir die Leistung auf Basis von externen Effekten abschaetzen wollen, wuerden 
wir uns genauer anschauen, welche externen Faktoren den groeßten Einfluss haben. 
Wir berechnen die Korrelation zwischen zwei Variablen, d.h. 
zwischen Item Fill Rate (IFR) und einer weiteren Variable (externe Faktoren). 
Wir erstellen Modelle, um IFR mit den externen Faktoren zusammen abzubilden. 
Um weitere Erkenntnisse zu schließen, wuerden wir weitere Kombinationen aus 
IFR mit den verschiedenen externen Faktoren modellieren. Die Kombination mit den 
groeßten Einfluss auf die Leistung der Logistik-Dienstleister schauen wir uns
genauer an. Da wir jedoch hier nur auf die Datenbeschaffung eingehen sollen,
wollen wir die Erklaerung zum Modelling, Testing und Bewertung hier nicht
mehr weiterfortfuehren.





