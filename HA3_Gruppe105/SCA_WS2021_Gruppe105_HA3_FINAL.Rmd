---
title: "SCA_WS2021_Gruppe105_HA3"
output:
  word_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Datenanalyse

```{r}
rm(list = ls())
#library("tidyverse")
library("dummies")
library("ggplot2")
library("Metrics")
library("dplyr")
library("tidyverse")
library("zoo")
library("forecast")
```


```{r cars}
externals = read.csv2("externals10.csv")
services = read.csv2("output_services_8Players_v0010.csv")
```


## Daten fuer die Modellierung vorbereiten

### Aufgabe 1: OTD und IFR nach berechnen
```{r}
#Erstellen von Periode-Variable
services$Periode = sprintf("%02d%02d", services$Year, services$Month)
```

```{r}
# OTD einzelnd pro Service Zeile berechnen
services$OTD = services$DaysExecuted <= services$DaysScheduled
services$IFR = services$QExecuted / services$QScheduled

# Aggregieren und Durchschnitt der OTD-Rate nach Lieferant berechnen
OTDdf = data.frame(aggregate(OTD ~ vendor, data = services, mean))
IFRdf = data.frame(aggregate(IFR ~ vendor, data = services, mean))

# Aufsteigende sortierte Darstellung
OTDdf = OTDdf[order(OTDdf$OTD),]
IFRdf = IFRdf[order(IFRdf$IFR),]

# Auf die 4. Nachkommastelle runden
OTDdf[2] = round(OTDdf$OTD, 4) 
IFRdf[2] = round(IFRdf$IFR, 4)

# DataFrame anzeigen
OTDdf
IFRdf
```

### Aufgabe 2: IFR je Warehousing-DL fuer 2020/12 in Japan
```{r}
# Aggregieren durchschnittlicher IFR-Rate nach Warehousing-DL in Japan in 202012
dfWarehousingJapanIFR = data.frame(aggregate(IFR ~ vendor + region + Periode,
                                data = subset(services,
                                              region =="Japan" &
                                              service == "Warehousing" &
                                              Periode == "202012"), mean))

# IFR auf die 4. Nachkommastelle runden
dfWarehousingJapanIFR[4] = round(dfWarehousingJapanIFR$IFR, 4)

#DataFrame anzeigen
dfWarehousingJapanIFR 
```

### Aufgabe 3: OTD je Shipping‐DL fuer 2020/12 in Japan
```{r}
# Aggregieren durchschnittlicher IFR-Rate nach Warehousing-DL in Japan
dfShippingJapanOTD = data.frame(aggregate(OTD ~ vendor + region + Periode,
                             data = subset(services,
                                           region =="Japan" &
                                           service == "Shipping" &
                                           Periode == "202012"), mean))

# OTD auf die 4. Nachkommastelle runden
dfShippingJapanOTD[4] = round(dfShippingJapanOTD$OTD, 4)

#DataFrame anzeigen
dfShippingJapanOTD
```

## Modellierung: Warehousing

### Aufgabe 4: CPS Warehousing mit Region und Periode anzeigen
```{r}
# Spalte Periode für externals erzeugen um mergen zu erleichtern.
externals$Periode = sprintf("%02d%02d", externals$Year, externals$Month)

# CPS Warehousing subset
cps_wh = services[services$vendor == "CPS Warehousing",]

# cps_wh und externals in neuem Dataframe auf Periode und Region mergen.
cps_wh_externals = merge(cps_wh, externals, by = c("region","Periode"))

# Output
cps_wh_externals %>% head()
```

### Aufgabe 5: Korrelation zwischen externen Faktoren und der IFR des WH‐DL  
(a) Unsortierte Tabelle der Korrelation der externen Effekte und der IFR
```{r}
correlations = data.frame(cor(cps_wh_externals$IFR, 
                              cps_wh_externals[, c(21:42)]))

# t() transponiert das DataFrame (bzw. dreht das DF um 90 Grad) 
correlations = t(correlations)

# Tabellennamen unbenennen
colnames(correlations) = c("Korrelation zu IFR")

# Auf vierte Nachkommastelle runden
correlations = round(correlations, 4)

# DataFrame anzeigen
correlations
```
(b) Tabelle mit den 5 am starksten zur IFR korrelierenden externen Effekten und deren Korrelation zur IFR 
```{r}
correlations_ordered = data.frame(
                       Features = row.names(correlations), correlations)
rownames(correlations_ordered) <- NULL

# Korrelationen sind stark, wenn sie nahe 1 oder nahe -1 sind, 
# daher müssen die Absoluten Werte genommen werden.
correlations_ordered$Korrelation.zu.IFR =
abs(correlations_ordered$Korrelation.zu.IFR) 

# Fuenf staerksten korrelierenden externen Effekte zu IFR
correlations_ordered = 
  correlations_ordered[order(-correlations_ordered$Korrelation.zu.IFR),] 

# Ersten fuenf Zeilen anzeigen
head(correlations_ordered, 5)
```
(c) Korrelations‐Plot fuer diese 5 externen Faktoren
```{r}
#TODO IFR hat gefehlt
# Correlation Plot erzeugen 
ggpairs(cps_wh_externals[, c("IFR","AvgHealth", "InternetStability", 
                             "BusinessConfidence", "ParkingSpaceAvailability", "Congestion")], 
        
# ohne Visualisierung des Fortschritts der Erstellung des plots
progress = FALSE,
        
# mit Visualisierung einer Glaettungslinie und Aenderung der Farbe der               
# Punkte, damit Linie erkennbar
lower = list(continuous = wrap("smooth_loess", colour = "steelblue1")))
```

### Aufgabe 6: Baseline erzeugen zur Guetevergleich unseres Modells
```{r}
# Baseline ist durschnittlicher IFR vom Monat.
cps_wh_externals = cps_wh_externals %>% 
  aggregate(IFR ~ Periode, data = ., mean) %>% 
  merge(cps_wh_externals, ., by = c("Periode"))

# Entferne hinzugefügtes .X und .y von Spaltennamen
colnames(cps_wh_externals) = gsub('\\.x','',names(cps_wh_externals))
colnames(cps_wh_externals) = gsub('\\.y','',names(cps_wh_externals))

# Spalten richtig benennen
colnames(cps_wh_externals)[2] = "Region"
colnames(cps_wh_externals)[43] = "Baseline"

# Auf die vierte Nachkommastelle runden
cps_wh_externals$IFR = round(cps_wh_externals$IFR, 4)
cps_wh_externals$Baseline = round(cps_wh_externals$Baseline, 4)

# Tabellenkopf ausgeben
cps_wh_externals[, c("Periode", "Region", "IFR", "Baseline")] %>% head()
```
Begruendung zu Aufgabe 6:
Da wir eine Lineare Regression durchfuehren wollen, um die IFR mit Hilfe der 
externen Effekte vorherzusagen, haben wir eine Baseline erzeugt, um die Guete 
unseres Modells vergleichen zu koennen. Hierbei haben wir uns fuer den 
Mittelwert von IFR entschieden, die nach den Perioden 2016.01 bis 2020.12 fuer 
alle Regionen aggregiert wurde. Hierbei koennen wir ausschließen, dass zunaechst 
die Regionen einen Einfluss auf das IFR hat. 


### Aufgabe 7: Visualisierung der Baseline (2016-2020) und die IFR fuer Shanghai
```{r}
plot_data = cps_wh_externals[(cps_wh_externals$Year >= 2016 | cps_wh_externals$Year <= 2020) & cps_wh_externals$Region == "Shangh",]
plot_data = plot_data[, c("Periode", "IFR", "Baseline")] %>% 
            aggregate(. ~ Periode, data = ., mean)

baseline_plot_data = plot_data[, c("Periode", "Baseline")]
baseline_plot_data$type = "Baseline"
colnames(baseline_plot_data)[2] = "data"

ifr_plot_data = plot_data[, c("Periode", "IFR")]
ifr_plot_data$type = "IFR"
colnames(ifr_plot_data)[2] = "data"

plot_final_data = rbind(baseline_plot_data, ifr_plot_data)
plot_final_data$Periode = as.yearmon(plot_final_data$Periode, "%Y%m")

ggplot(data = plot_final_data, aes(x = Periode, y=data, colour = type)) + 
  geom_line() +
  theme(axis.text.x = element_text(angle=90, vjust = 0.5, hjust=2, size=6), 
    legend.position = c(.16, .95),
    legend.justification = c("right", "top"),
    legend.box.just = "right",
    legend.margin = margin(6, 6, 6, 6)
   ) + 
  xlab("Period") + 
  ylab("IFR Shanghai") +
  ggtitle(label = "CPS Warehousing IFR and Baseline from 2016 to 2020") +
# Clean up
rm(plot_data, baseline_plot_data, ifr_plot_data, plot_final_data)
```


### Aufgabe 8: Baseline Bewertung fuer den gewaehlten WH-DL nach MAE und MAPE
```{r}
# DataFrame erzeugen, dass bei auf die Beschreibung ("Model") leer bzw. 0 ist
evaluation = data.frame(Model = "Baseline",
                        MAE = numeric(1),
                        sMAPE = numeric(1))

# MAE berechnen
evaluation[evaluation$Model == "Baseline",]$MAE = 
  mean(abs(cps_wh_externals$IFR - cps_wh_externals$Baseline))

# sMAPE berechnen
evaluation[evaluation$Model == "Baseline",]$sMAPE = 
  smape(cps_wh_externals$IFR, cps_wh_externals$Baseline)

# MAE und sMAPE auf vierte Nachkommastelle runden
evaluation[2] = round(evaluation$MAE,4)
evaluation[3] = round(evaluation$sMAPE,4)

# DataFrame anzeigen
evaluation

# Kommentar: Wir nehmen sMAPE als Fehlerkennzahl, da MAPE gleich 0 ergibt und 
# somit nicht bewertbar ist.
```

### Aufgabe 9: Aufteilung des DFs in Trainings‐ (80%) und ein Test‐Set (20%)
```{r}
# Gegenmassnahme zum Overfitting: Aufteilung in Trainings- & Test-Data Set

# Erzeuge iterative Zahlenreihe statt Periode
cps_wh_externals <- transform(cps_wh_externals,
                              PeriodeNumber=as.numeric(factor(Periode)))

# Einen zufaelligen Zustand herstellen 
set.seed(4141)

# Zufallsaufwahl erstellen: 
# Aus der Liste von Zahlen 1 bis Laenge von cps_wh_externals werden 80% gewaehlt
zufall = sample(1:nrow(cps_wh_externals), nrow(cps_wh_externals) * 0.8)

# Die Eintraege in der Zufallsauswahl gehen in das TrainingsSet
cps_wh_externalsTraining = cps_wh_externals[zufall, ]

# Die Eintraege nicht in der Zufallsauswahl gehen in das TestSet (20%)
cps_wh_externalsTest = cps_wh_externals[-zufall, ]

#Tabellenkopf ausgeben
head(cps_wh_externalsTest)
head(cps_wh_externalsTraining)
```



### Aufgabe 10: Modelle erstellen mit Forward Selection Variante der Wrapper Methode

```{r}
# Wir schauen uns die Korrelation zwischen den Variablen an, um eine
# Multikollinearitaet zu vermeiden. Wenn eine Korrelation 0.8 uebersteigt,
# wird einer der Variablen aussortiert.
cor(cps_wh_externals[, c("IFR", "AvgHealth", "InternetStability", "BusinessConfidence", "ParkingSpaceAvailability", "Congestion")], cps_wh_externals[, c("IFR", "AvgHealth", "InternetStability", "BusinessConfidence", "ParkingSpaceAvailability", "Congestion")]) %>% as.data.frame()

# TODO: Neues Kommentar
# Kommentar: 
# Eine starke Korrelation wurde zwischen InternetStability und BusinessCondifdence, 
# sowie zwischen Congestion und ParkingSpaceAvailability gefunden. 
# Fuer die Erstellung unseres Modells werden BusinessConfidence und Congestion nicht 
# betrachtet.

# Kommentar:
# Um eine starke Multikollinearität zwischen BusinessConfidence und 
# InternetStability zu vermeiden, da beide Variablen Werte ueber 0.8 zeigen,
# nehmen wir BusinessConfidence raus und lassen InternetStability drin.
# Dies gilt auch fuer Congestion und ParkingSpaceAvailability.
# Daher schließen wir Congestion aus und betrachten ParkingSpaceAvailability.
```

```{r}
# 1. Iteration

# Modelle erstellen mit untransformierter unabhaengiger Variable
# Wir betrachten jeweils nur ein Merkmal (univariater Datenanalyse)
m1_1 = lm(IFR ~ AvgHealth, data = cps_wh_externalsTraining)
m1_2 = lm(IFR ~ InternetStability, data = cps_wh_externalsTraining)
# m1_3 = lm(IFR ~ BusinessConfidence, data = cps_wh_externalsTraining)
m1_4 = lm(IFR ~ ParkingSpaceAvailability, data = cps_wh_externalsTraining)
# m1_5 = lm(IFR ~ Congestion, data = cps_wh_externalsTraining)

# DF erweitern
evaluation = rbind(data.frame(
                   Model = c("m1_1", "m1_2", "m1_4"),
                   MAE = numeric(1), 
                   sMAPE = numeric(1),
                   R = numeric(1), 
                   adjR = numeric(1))) 
# MAE berechnen
evaluation[evaluation$Model == "m1_1",]$MAE = mean(abs(m1_1$residuals)) 
evaluation[evaluation$Model == "m1_2",]$MAE = mean(abs(m1_2$residuals)) 
# evaluation[evaluation$Model == "m1_3",]$MAE = mean(abs(m1_3$residuals)) 
evaluation[evaluation$Model == "m1_4",]$MAE = mean(abs(m1_4$residuals)) 
# evaluation[evaluation$Model == "m1_5",]$MAE = mean(abs(m1_5$residuals)) 

# sMAPE berechnen
evaluation[evaluation$Model == "m1_1",]$sMAPE = 
  smape(m1_1$model$IFR, m1_1$fitted.values)
evaluation[evaluation$Model == "m1_2",]$sMAPE = 
  smape(m1_2$model$IFR, m1_2$fitted.values) 
# evaluation[evaluation$Model == "m1_3",]$sMAPE = 
# smape(m1_3$model$IFR, m1_3$fitted.values) 
evaluation[evaluation$Model == "m1_4",]$sMAPE = 
  smape(m1_4$model$IFR, m1_4$fitted.values) 
# evaluation[evaluation$Model == "m1_5",]$sMAPE = 
# smape(m1_5$model$IFR, m1_5$fitted.values) 

#R^2 berechnen
evaluation[evaluation$Model == "m1_1",]$R = summary(m1_1)$r.squared
evaluation[evaluation$Model == "m1_2",]$R = summary(m1_2)$r.squared
# evaluation[evaluation$Model == "m1_3",]$R = summary(m1_3)$r.squared
evaluation[evaluation$Model == "m1_4",]$R = summary(m1_4)$r.squared
# evaluation[evaluation$Model == "m1_5",]$R = summary(m1_5)$r.squared

# adjusted R^2 berechnen
evaluation[evaluation$Model == "m1_1",]$adjR = summary(m1_1)$adj.r.squared 
evaluation[evaluation$Model == "m1_2",]$adjR = summary(m1_2)$adj.r.squared 
# evaluation[evaluation$Model == "m1_3",]$adjR = summary(m1_3)$adj.r.squared 
evaluation[evaluation$Model == "m1_4",]$adjR = summary(m1_4)$adj.r.squared 
# evaluation[evaluation$Model == "m1_5",]$adjR = summary(m1_5)$adj.r.squared 

# Runden auf die 4. Nachkommastelle
evaluation[2] = round(evaluation$MAE, 4)
evaluation[3] = round(evaluation$sMAPE , 4)
evaluation[4] = round(evaluation$R, 4)
evaluation[5] = round(evaluation$adjR, 4)
evaluation

# Kommentar: Wir entscheiden uns fuer das Model m1_1 mit den niedrigsten MAE und 
# sMAPE. Das R^2 und adjustierte Bestimmtheitsmaß R^2 ist in unserer Betrachtung 
# groeßer als in den anderen Modellen. Daher nehmen wir das Model m1_1 und
# fahren damit fort.
```


```{r}
# 2. Iteration
m1_1_2 = lm(IFR ~ AvgHealth + InternetStability, 
            data = cps_wh_externalsTraining)
# m1_1_3 = lm(IFR ~ AvgHealth + BusinessConfidence, 
# data = cps_wh_externalsTraining)
m1_1_4 = lm(IFR ~ AvgHealth + ParkingSpaceAvailability, 
            data = cps_wh_externalsTraining)
#m1_1_5 = lm(IFR ~ AvgHealth + Congestion, data = cps_wh_externalsTraining)

# DF erweitern
evaluation = rbind(data.frame(
                   Model = c("m1_1_2", "m1_1_4"),
                   MAE = numeric(1), 
                   sMAPE = numeric(1),
                   R = numeric(1), 
                   adjR = numeric(1))) 
# MAE berechnen
evaluation[evaluation$Model == "m1_1_2",]$MAE = mean(abs(m1_1_2$residuals)) 
# evaluation[evaluation$Model == "m1_1_3",]$MAE = mean(abs(m1_1_3$residuals)) 
evaluation[evaluation$Model == "m1_1_4",]$MAE = mean(abs(m1_1_4$residuals)) 
# evaluation[evaluation$Model == "m1_1_5",]$MAE = mean(abs(m1_1_5$residuals)) 

# sMAPE berechnen
evaluation[evaluation$Model == "m1_1_2",]$sMAPE = 
  smape(m1_1_2$model$IFR, m1_1_2$fitted.values)
# evaluation[evaluation$Model == "m1_1_3",]$sMAPE = 
#  smape(m1_1_3$model$IFR, m1_1_3$fitted.values)
evaluation[evaluation$Model == "m1_1_4",]$sMAPE = 
  smape(m1_1_4$model$IFR, m1_1_4$fitted.values)
#evaluation[evaluation$Model == "m1_1_5",]$sMAPE = 
#  smape(m1_1_5$model$IFR, m1_1_5$fitted.values) 

#R^2 berechnen
evaluation[evaluation$Model == "m1_1_2",]$R = summary(m1_1_2)$r.squared
# evaluation[evaluation$Model == "m1_1_3",]$R = summary(m1_1_3)$r.squared
evaluation[evaluation$Model == "m1_1_4",]$R = summary(m1_1_4)$r.squared
# evaluation[evaluation$Model == "m1_1_5",]$R = summary(m1_1_5)$r.squared

# adjusted R^2 berechnen
evaluation[evaluation$Model == "m1_1_2",]$adjR = summary(m1_1_2)$adj.r.squared 
# evaluation[evaluation$Model == "m1_1_3",]$adjR = summary(m1_1_3)$adj.r.squared 
evaluation[evaluation$Model == "m1_1_4",]$adjR = summary(m1_1_4)$adj.r.squared 
# evaluation[evaluation$Model == "m1_1_5",]$adjR = summary(m1_1_5)$adj.r.squared 

# Runden auf die 4. Nachkommastelle
evaluation[2] = round(evaluation$MAE, 4)
evaluation[3] = round(evaluation$sMAPE , 4)
evaluation[4] = round(evaluation$R, 4)
evaluation[5] = round(evaluation$adjR, 4)
evaluation

# Kommentar: Wir entscheiden uns fuer das Model m1_1_4 mit den niedrigsten MAE 
# und sMAPE. Das R^2 und adjustierte Bestimmtheitsmaß R^2 ist in unserer 
# Betrachtung groeßer als in den anderen Modellen. Daher nehmen wir das Model 
# m1_1_4 und fahren damit fort.
```

```{r}
# 3. Iteration
m1_1_4_2 = lm(IFR ~ AvgHealth + ParkingSpaceAvailability + 
                InternetStability, data = cps_wh_externalsTraining)
#m1_1_4_3 = lm(IFR ~ Periode + AvgHealth + ParkingSpaceAvailability + 
#                BusinessConfidence, data = cps_wh_externalsTraining)
#m1_1_4_5 = lm(IFR ~ Periode + AvgHealth + ParkingSpaceAvailability + 
#                Congestion, data = cps_wh_externalsTraining)

# DF erweitern
evaluation = rbind(data.frame(
                   Model = c("m1_1_4_2"),
                   MAE = numeric(1), 
                   sMAPE = numeric(1),
                   R = numeric(1), 
                   adjR = numeric(1))) 
# MAE berechnen
evaluation[evaluation$Model == "m1_1_4_2",]$MAE = mean(abs(m1_1_4_2$residuals)) 
#evaluation[evaluation$Model == "m1_1_4_3",]$MAE = mean(abs(m1_1_4_3$residuals)) 
#evaluation[evaluation$Model == "m1_1_4_5",]$MAE = mean(abs(m1_1_4_5$residuals)) 

# sMAPE berechnen
evaluation[evaluation$Model == "m1_1_4_2",]$sMAPE = 
  smape(m1_1_4_2$model$IFR, m1_1_2$fitted.values)
# evaluation[evaluation$Model == "m1_1_4_3",]$sMAPE = 
#  smape(m1_1_4_3$model$IFR, m1_1_3$fitted.values)
# evaluation[evaluation$Model == "m1_1_4_5",]$sMAPE = 
#  smape(m1_1_4_5$model$IFR, m1_1_4$fitted.values)

#R^2 berechnen
evaluation[evaluation$Model == "m1_1_4_2",]$R = summary(m1_1_4_2)$r.squared
# evaluation[evaluation$Model == "m1_1_4_3",]$R = summary(m1_1_4_3)$r.squared
# evaluation[evaluation$Model == "m1_1_4_5",]$R = summary(m1_1_4_5)$r.squared

# adjusted R^2 berechnen
evaluation[evaluation$Model == "m1_1_4_2",]$adjR = summary(m1_1_4_2)$adj.r.squared 
# evaluation[evaluation$Model == "m1_1_4_3",]$adjR = summary(m1_1_4_3)$adj.r.squared 
# evaluation[evaluation$Model == "m1_1_4_5",]$adjR = summary(m1_1_4_5)$adj.r.squared 

# Runden auf die 4. Nachkommastelle
evaluation[2] = round(evaluation$MAE, 4)
evaluation[3] = round(evaluation$sMAPE , 4)
evaluation[4] = round(evaluation$R, 4)
evaluation[5] = round(evaluation$adjR, 4)
evaluation


# Kommentar: Das Modell m1_1_4_2 hat sich im Vergleich zu Modell m1_1_4 bei 
# der Betrachtung von MAE verbessert, was jedoch ausfaellt ist das sMAPE sich
# verschlechtert hat. Hingegen haben sich R^2 und das adjustierte Bestimmt-
# heitsmaß R^2 erhoeht. Wir betrachten das Modell m1_1_4_2 als unser bestes
# Modell.
```

```{r}
summary(m1_1_4)
summary(m1_1_4_2)
```




Kommentar: Bei der genauen Analyse der Modelle stellen wir fest, dass das 
Multiple R-squared und Adjusted R-squared von Modell m1_1_4_2 hoeher ist als 
das von Modell m1_1_4. Dies spricht dafuer, dass das Modell  m1_1_4_2 eine 
bessere Vorhersagegenauigkeit hat, die sich durch die zusaetzlichen Variablen 
verbessert hat. Das Residual standard error ist bei dem verbesserten Modell 
kleiner als bei dem vorherigen Modell m1_1_4, was auch ein Indiz dafuer ist, 
dass wir das Modell m1_1_4_2 weitehrin verwenden werden.


*Overfitting ueberpruefen*
Zum Schluss vergleichen wir Trainings- und Test-Daten und bewerten die zwei 
Modelle. Dabei ueberpruefen wir das endgueltige Modell Modell m1_1_4_2 am Ende 
auf Overfitting indem die Fehlerkennzahlen fuer TestSet berechnen. 
Dies verlangt, dass fuer das TestSet Vorhersagen erstellt werden mit der 
`predict()` Funktion.

*Overfitting ueberpruefen*
Zum Schluss vergleichen wir wie unser Modell sich schlägt wenn wir es mit 
den Testdaten überprüfen. Damit wird einem Overfitting vorgebeugt, also das 
unsere Modell zugenau auf die Trainingsdaten angepasst wurde. 
`predict()` Funktion.
```{r}

#TODO Geändert
# Bestes Modell aus evaluation filtern und am Ende an dem TestSet anhaengen
evaluation = data.frame(subset(evaluation[,1:3], Model == "m1_1_4_2"))

# Modell mit Testdaten testen
pred1 = predict(m1_1_4_2, cps_wh_externalsTest)  

# Data Frame erweitern
evaluationNeu = rbind(data.frame(Model = c("Test_Model"),
                                          MAE = numeric(1),
                                          sMAPE = numeric(1)))
# MAE von TestModel berechnen
evaluationNeu[evaluationNeu$Model == "Test_Model", ]$MAE = 
                                    mean(abs(cps_wh_externalsTest$IFR - pred1))
# sMAPE von TestModel berechnen
evaluationNeu[evaluationNeu$Model == "Test_Model", ]$sMAPE = 
                                    smape(cps_wh_externalsTest$IFR, pred1)

# Zeilen verbinden
test_rbind = rbind(evaluation, evaluationNeu)

# Runden und anzeigen
test_rbind[2] = round(test_rbind$MAE, 4)
test_rbind[3] = round(test_rbind$sMAPE, 4)

# Tabellenkopf anzeigen
test_rbind

# Kommentar: Das beste Modell m1_1_4_2 und das jetzige Test-Modell weisen 
# aehnliche Zahlen auf. Ein Overfitting ist hierbei nicht zu finden.
```


### Aufgabe 11: Quantitative Modell Bewertung im Vergleich mit der Baseline
```{r}
# Bewertung von Baseline Modell
# DataFrame erzeugen
evaluation = data.frame(Model = "Baseline",
                        MAE = numeric(1),
                        sMAPE = numeric(1))

# MAE von Baseline Modell berechnen
evaluation[evaluation$Model == "Baseline",]$MAE = 
  mean(abs(cps_wh_externals$IFR - cps_wh_externals$Baseline))

# sMAPE von Baseline Modell berechnen
evaluation[evaluation$Model == "Baseline",]$sMAPE = 
  smape(cps_wh_externals$IFR, cps_wh_externals$Baseline)

# Auf die vierte Nachkommastelle runden
evaluation[2] = round(evaluation$MAE, 4)
evaluation[3] = round(evaluation$sMAPE, 4)

# Vergleich der Fehler beider Modelle anzeigen
evaluation
```
Kommentar: Wir vergleichen uns besten Modell m1_1_4_2_3 mit unserer Baseline.
Hierbei gab es eine Verbesserung im Modell m1_1_4_2_3 im Vergleich zur 
Baseline, da die Fehlerkennzahlen MAE und sMAPE kleiner sind als die Fehlerwerte 
vom Baseline Modell.


### Aufgabe 12: Wette - IFR soll in 2021/01 in allen Regionen ueber 0.85 sein 
```{r}
# Da wir 2021/01 die Werte berechnen wollen, setzen wir fuer unsere Vorhersage 
# die historischen Januars von 2016 bis 2020 voraus
cps_wh_externals = cps_wh_externals[cps_wh_externals$Month == "1",] 

# Modell erstellen fuer alle Regionen auf Basis des besten Modells m1_1_4_2 und 
# den Baseline Werten
predictModel = lm(IFR ~ Periode, data = cps_wh_externals)
predictModelBaseline = lm(Baseline ~ Periode, data = cps_wh_externals)

# Vorhersage Baseline und bestes Modell erstellen 
# mit der Funktion predict(model, data)
predictDFBaseline = 
  data.frame(predict(predictModelBaseline, data=cps_wh_externals))

predictDF_bestmodel = 
  data.frame(predict(m1_1_4_2, data=cps_wh_externals))

# Spalte umbenennen
colnames(predictDFBaseline)  = "Vorhersage Baseline"
colnames(predictDF_bestmodel)  = "Vorhersage Bestes Modell"

# Runden auf die vierte Nachkommastelle
predictDFBaseline[1] = round(predictDFBaseline$Vorhersage, 4)
predictDF_bestmodel[1] = round(predictDF_bestmodel$Vorhersage, 4)

# Tabellenkopf anzeigen
head(predictDFBaseline)
head(predictDF_bestmodel)

wilke = externals[,"Year"==22021]
externals_202101 = externals[externals$Year == "2021" & externals$Month=="1",]
[evaluation$Model == "m1_1",]
wilke
```
Kommentar zu Aufgabe 12: Wir nehmen alle historischen Werte von Januar, um den 
Januar 2021 zu bestimmen. Wir gehen die Wette ein, da die Vorhersage basierend
auf unserem Baseline-Modell und unserem Modell m1_1_4_2 ueber 0.85 liegt. 
Dafuer haben wir das beste Modell m1_1_4_2 und die Baseline Werte zur Grunde 
gelegt und ueberprueft, ob die Vorhersagewerte ueber 0.85 liegen. 
In diesem Fall zeigt uns das Baseline-Modell, dass unsere Vorhersagewerte ueber 
0.85 und beim Modell m1_1_4_2 auch ueberwiegend ueber 0.85. Wir wuerden daher
mit hoher Wahrscheinlichkeit die Wette gewinnen.



## Entscheidung

### Aufgabe 13: Regressionsmodell Implementierung in Unternehmensprozess
Antwort zu Aufgabe 13:
*Nutzer*: Da unser Regressionsmodell im kommenden Jahr langfristig in die 
Unternehmensprozesse implementiert werden soll, stellen wir uns die Fragen, 
welche Nutzer und welche Prozesse vom Regressionsmodell profitieren koennen, 
und in welcher Form die Loesung bereitgestellt werden soll. 
Hierbei nehmen wir an, dass die Geschaeftsfuehrung einen Vorrang auf 
Informationsbereitstellung hat, da diese Stakeholder wichtige und 
langfristige Entscheidungen im Unternehmen treffen werden. 
Diese Entscheidungen koennen sie mit Hilfe des Regressionsmodells treffen, da 
das Modell eine Uebersicht ueber den Einfluss der Externen Effekte auf die 
Leistung der Logistikdienstleister darstellt. Dabei wurden fuenf externe 
Effekte identifiziert, die vergleichsweise den groeßten Einfluss auf die 
Logistikdienstleister haben. Weitere Nutzer koennen neben der Geschaeftsfuehrung 
auch die Abteilungen der Logistik sowie Finanz-Abteilung sein, da das Modell 
wichtige Logistik-Kennzahlen wie das IFR abbildet.
*Prozesse*: Anhand des Regressionsmodells kann beispielsweise die Logistik-
Abteilung Abschaetzungen machen, wie die Leistungen der Logistikdienstleister in 
einem bestimmten Zeitraum war und durch welche externen Faktoren diese Leistung 
beeinflusst wurde. Hierbei kann die Logistik-Abteilung beispielsweise durch die 
Erkenntnisgewinnung die Lieferprozesse besser bewerten und steuern und mit den 
Logistikdienstleistern bessere SLA Bedingungen aushandeln. 
Wir fokussieren uns auf diese fuenf externen Faktoren, die am staerksten mit
IFR korrelieren: Periode, AvgHealth, ParkingSpaceAvailability, InternetStability 
und Congestion. Da jedoch BusinessConfidence und Congestion stark mit anderen
Variablen korrelieren, nehmen wir diese beiden Variablen raus, um eine starke 
Multikollinearität zu vermeiden.
*Loesungsbereitstellung*: Die Loesungsbereitstellung kann in verschiedenen 
Formen erfolgen. Da unser Modell auf R basiert, koennen wir Visualisierungs-
software, wie z.B. MicroStrategy oder Microsoft Power BI, verwenden unter der
Bedingung, dass die Lizensen und der Zugang im Unternehmen vorhanden sind.
Andernfalls kann die Loesungsbereitstellung auch ueber Excel oder R-Studio 
erfolgen. Von PDF oder Papier Präsentation des Modells raten wir ab.
*Stellungnahme zur Datenbeschaffung*:
Bei der Datenbeschaffung gehen wir entlang der folgenden Phasen vor.
1. Unternehmen verstehen / Zielsetzung: 
Zuerst muessen wir das Unternehmen besser verstehen, um festzulegen, welche
Daten wir benoetigen. Generell wollen wir bei der Distribution von Limonalytics 
fuer die naechsten Monate im Voraus planen und ein Modell erstellen, um deren 
Leistung auf Basis von externen Effekten abzuschaetzen. 
Das Ziel ist hierbei anhand eines Regressionsmodells zukuenftige Entscheidungen 
fundiert und effizient abzuleiten.
Hierbei schauen wir uns bei der Datenbeschaffung die externen Effekte der 
letzten 60 Monate (2016‐2020) an sowie die Leistungen der jeweiligen 
Logistikdienstleister in den jeweiligen Regionen.
2. Daten sammeln: Fuer unsere Datensammlung benoetigen Daten aus verschiedenen 
Bereichen. Wir fokussieren uns auf die Logistikzentralen an den jeweiligen 
Standorten, die uns Daten zu den Logistik-Dienstleistungen und externen Faktoren 
beschaffen koennten. Andernfalls wuerden wir auf unseren lokalen Servern 
Durchsuchungen bestreben, Befragungen bei der Logistikabteilung durchfuehren, 
um mehr Daten zu externen Faktoren und Logstikdienstleistungen sammeln zu 
koennen oder uns an externe Datenquellen im Internet wenden.
3. Daten-Analyse: Bei der Datenbeschaffung ist es wichtig die Daten immer wieder
zu analysieren, um die Datenqualitaet zu erhoehen und falsche Vorhersagen zu 
vermeiden. Nach der Datenanalyse kommt im naechsten Schritt die Datenbereinigung 
sowie Datentransformation, um unseren aktuellen Unternehmenszustand sowie 
Vorhersage so praezise wie moeglich abzubilden.
4. Kennzahlen festlegen: Um weitere moeglichen relevanten Daten zu beschaffen,
wuerden wir als naechstes Kennzahlen festlegen. 
Der Zeitraum der Datensaetze ist bekannt und liegt zwischen 2016 und 2021.
Da Logistikdienstleistungen nicht immer mit Daten von externen Faktoren zu-
sammengefasst sind, wuerden wir DL und externen Faktoren basierend auf den
Perioden zusammenfassen. Je nach Ziel beschraenken wir uns auf bestimmte 
Regionen und Dienstleister. 
Da wir die Leistung auf Basis von externen Effekten abschaetzen wollen, wuerden 
wir uns genauer anschauen, welche externen Faktoren den groeßten Einfluss haben. 
Da wir jedoch hier nur auf die Datenbeschaffung eingehen sollen,
wollen wir die Erklaerung zum Modelling, Testing und Bewertung hier nicht
mehr weiterfortfuehren.

